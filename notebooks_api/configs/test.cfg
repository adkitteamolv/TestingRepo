#! -*- coding: utf-8 -*-
import logging
from notebooks_api import auth

# context
URL_PREFIX = "/notebooks/api"
PROXY_PREFIX = "/notebooks/proxy"

# security
SECRET_KEY = "8896958076629c1711b991c4552e8c6616b9e2a94a2fcb7c038fd10b049f30ce"

# database
SQLALCHEMY_ECHO = False
SQLALCHEMY_POOL_SIZE = 1
SQLALCHEMY_POOL_TIMEOUT = 120
SQLALCHEMY_POOL_RECYCLE = 60
SQLALCHEMY_MAX_OVERFLOW = 10
SQLALCHEMY_DATABASE_URI = "postgresql+psycopg2://postgres:VRNFyxOl@fdc-qa-postgres-01.c9cg4zpreqvg.us-east-1.rds.amazonaws.com:5432/ai_logistics?options=-csearch_path=ai_logistics"
#SQLALCHEMY_DATABASE_URI = "postgresql+psycopg2://mosaic:mos11@2123@10.23.224.95:6524/ai_logistics?options=-csearch_path=ai_logistics"
#SQLALCHEMY_DATABASE_URI = "oracle+cx_oracle://system:oracle@oracle-12c/xe"
SQLALCHEMY_TRACK_MODIFICATIONS = False

# log
LOG_FORMAT = '[%(asctime)s] [%(levelname)s] [%(name)s] [project_id:%(project_id)s] [requestURI:%(url)s] [user: %(user_id)s] [source: %(pathname)s - %(module)s - %(funcName)s : %(lineno)d] [message: %(message)s]'
LOG_DIR = "/logs"
LOG_LEVEL = "INFO"
LOG_BACKUP_COUNT = 5
LOG_MAX_BYTES = 10000000
LOG_DIRECTORY = "/apps"

# FLASK-OIDC
OIDC_CLIENT_SECRETS = "client_secrets.json"
OIDC_ID_TOKEN_COOKIE_SECURE = False
OIDC_REQUIRE_VERIFIED_EMAIL = False
OIDC_USER_INFO_ENABLED = True
OIDC_OPENID_REALM = "mosaic-lens"
OIDC_SCOPES = ['openid', 'email', 'profile']
OIDC_INTROSPECTION_AUTH_METHOD =  "client_secret_post"
OIDC_VALID_ISSUERS = ['http://map-aws-dev-keycloak.hk.standardchartered.com/auth/realms/mosaic-lens']

# jupyter hub
HUB_BASE_URL = "http://notebooks-initiator-proxy:8000/notebooks/proxy/hub/api"
HUB_AUTH_TOKEN = "78a6f67cad1c4ee7a48132e311eb4f74"

# git config
VCS_BASE_URL = "http://mosaic-version-control:9000"

# pypi registry url
ARTIFACTORY = False
PYPI_URL = "https://pypi.org/simple"
CONDA_PYTHON_URL = "https://repo.anaconda.com/pkgs/main/linux-64/"
CONDA_R_URL = "conda-forge"
CRAN_URL = "https://cran.r-project.org/web/packages/available_packages_by_name.html#available-packages-Z"
#PYPI_URL = "https://clicktime.symantec.com/3RcAU4RH2cGhraSswK81TDC7Vc?u"
#PYPI_URL = "https://artifactory.global.standardchartered.com/artifactory/api/pypi/pypi/simple"
#PYPI_URL = "http://maxiq:Uns@vedD0cument1@35.168.48.43/repo/python3.6/pip3.6/simple/"
#CRAN_URL = "https://artifactory.global.standardchartered.com/artifactory/cran-release/src/contrib/"

CRAN_VERSION_URL = "https://cran.r-project.org/web/packages/{0}/index.html"
CRAN_ALL_VERSION_PACKAGE = "https://cran.r-project.org/src/contrib/Archive/{0}/?C=M;O=D"


#R_PACKAGE_REPO = "https://artifactory.global.standardchartered.com/artifactory/cran-release/"
R_PACKAGE_REPO = "http://cran.us.r-project.org"
CONDA_PYTHON_URL_ES = "https://repo.anaconda.com/pkgs/main/linux-64/"
CONDA_R_URL_ES = "https://repo.anaconda.com/pkgs/r/linux-64/"

# celery
CELERY_BROKER_URL = "amqp://guest:guest@rabbitmq.fdc-components.svc.cluster.local:5672"
CELERY_TIMEZONE = "PST8PDT"
CELERY_DEFAULT_QUEUE = "notebooks"
CELERY_ACKS_LATE = True

# skip auth for following URI
SKIP_AUTH = (
    "/metrics",
    "/github/",
    "/docs",
    "/flasgger_static/",
    "/rename/",
    "/v2/notebooks/",
    "/notebooks/update/content/",
    "/cull",
    "/summary/",
    "/healthz",
    "/v1/pods/trigger_alerts",
    "/ping"
)

# socket io
SOCKETIO_QUEUE = "amqp://guest:guest@rabbitmq.fdc-components.svc.cluster.local:5672"

# elasticsearch ip for pypi packages
ELASTIC_IP = "elasticsearch-master"
ELASTIC_PORT = 9200
ELASTIC_USE_SSL = False
ELASTIC_PASSWORD = "elasticsearch"
ELASTIC_USER = ""
ELASTIC_AUTH_REQ = False
PYPI_ALIAS_NAME = "pypi"
INDEX_REFRESH_INTERVAL = 3600  # in secs
CRAN_ALIAS_NAME = "cran"
CONDA_PYTHON_ALIAS_NAME = "conda"
CONDA_R_ALIAS_NAME = "conda-r"
# limit of containers per user
CONTAINER_LIMIT = 2

# web socket configs
SOCKET_URL = "http://mosaic-socketio:5000"
SOCKET_RESOURCE = "mosaic-socketio/socket.io"

# scheduler
SCHEDULER_URL = "http://notebooks-api:5000/notebooks/api/v1/spawner"
SCHEDULER_TOKEN = "i7wriewurwer076629werwer3232e8"

# monitor
MONITOR_URL = "http://monitor-backend-service:80/monitor"

# default resource
DEFAULT_RESOURCE = "Micro"

# testing
TESTING = False

GROUP = "/mosaic/mosaic-ai-logistics"

# validate license service
VALIDATE_LICENSE_BASE_URL = "http://license-service/"
SERVICE_ID = "notebook-api-service"

# connector details
UID = "catalog"
CONNECTOR_PYTHON_HOST = "connectors-backend-service"
CONNECTOR_PYTHON_PORT = "25333"
CONNECTOR_BASE_URL = "http://connection-manager/connections/" \
                                            "api/External/v1/external/getConnConfig"
CONNECTOR_PYTHON_HOST_SCHEDULE_JOB = "connectors-backend-service.insight.svc.cluster.local"
CONNECTOR_BASE_URL_SCHEDULE_JOB = "http://connection-manager.insight.svc.cluster.local/connections/api/External/v1/external/getConnConfig"
CONNECTOR_BACKEND_URL = "http://connectors-backend-service/connectors/"

# Recipe_project_id for automl
RECIPE_PROJECT_ID = "69574938-4d83-49b9-9344-bf3c7474dc98"

# input param service
GET_IN_PARAMS = "http://fdc-project-manager/project-manager/input-parameter/secured/api/v1/inputParameter/getInputParameterListForReferenceIdAndReferenceType"

# input param service
INPUT_PARAM_BASE_URL = "http://fdc-project-manager/project-manager/input-parameter/secured/api/v1"



# mosaic kubespawner url
MOSAIC_KUBESPAWNER_URL = "http://notebooks-api:5000/notebooks/api/v1/spawner/execute-notebook"
MOSAIC_KUBESPAWNER_BASE_URL = "http://notebooks-api:5000/notebooks/api/v1/spawner/"
MOSAIC_KUBESPAWNER = "http://notebooks-api:5000/notebooks/api/v1/spawner"
REFRACT_KUBESPAWNER_PLUGIN_EXEC_URL = "http://notebooks-api:5000/notebooks/api/v1/spawner/execute-job"

# backend url
MOSAIC_AI_SERVER = "http://mosaic-ai-backend:5000/registry/api"
NOTEBOOKS_API_SERVER_URL = "http://notebooks-api.insight.svc.cluster.local:5000/notebooks/api"
MOSAIC_AI_SERVER_SCHEDULER = "http://mosaic-ai-backend.insight.svc.cluster.local:5000/registry/api"

# mosaicml db url
DB_URL = "http://auto-ml-service/auto-ml/api/v1/exp"

# namespace
NAMESPACE = "insight"

# console-backend url
CONSOLE_BACKEND_URL = "http://fdc-project-manager/project-manager/mosaic-console-backend"

# user-management
USER_MANAGEMENT_URL =  "http://user-management:8094/usermgm"
MULTI_TENANT_USER_MANAGEMENT_URL =  "http://user-management:8094/usermgm"

METERING_BACKEND_URL = "http://mosaic-metering-backend:4000/metering/api"

# skip-project-auth
SKIP_PROJECT_AUTH = ("/progress")

MINIO_BUCKET = "fdc-insights"
# minio-data-config

MINIO_DATA_BUCKET = "fdc-insights"
POD_DATA_PATH = "/sandbox_shared/logistics/minio/"


# jwt
JWT_SECRET = "GkeE6mK7CBt4EUS03Zl0HgMcnEQ/RL+MnqksukdjbS2JJxXY3wgvl+Naldk5yLJ/SHyWmHugQ"
JWT_ALGORITHM = "HS256"

# notebooks url
NOTEBOOKS_API_SERVER = "http://notebooks-api.insight.svc.cluster.local:5000/notebooks/api"
# NodePool Keys/Tolerations
NODE_AFFINITY_REQUIRED_KEY = "mosaic"
NODE_AFFINITY_REQUIRED_VALUES = "ailogistics"
NODE_AFFINITY_REQUIRED_OPERATOR = "NotIn"
TOLERATIONS_KEY = "environment"
TOLERATIONS_VALUE = "scb"
TOLERATIONS_OPERATOR = "Equal"
TOLERATIONS_EFFECT = "NoSchedule"
# To display GPU in resources: "nvidia,amd"
#GPU_RESOURCE_KEYS = "nvidia,amd"
GPU_RESOURCE_KEYS = ""
DEFAULT_HOST = "qa.fdc.leni.ai"
SAS_SERVER_PORT = "8989"
DEPLOYMENT_NAME = "test-ai-logistics"
RUN_MODE= "developer"
SAS_SESSION_TIMEOUT_IN_MINUTES = "720m"

VALIDATOR_SA_FLAG = True
GIT_NAMESPACE = "root"
GIT_REGISTRY = "937361994640.dkr.ecr.us-east-1.amazonaws.com"
GIT_TOKEN = "VnPKvjyKoLjs7NF_g2sQ"

# user impersonation flag
USER_IMPERSONATION_FLAG = False
USER_IMPERSONSATION_PREFIX = "SCB"
USER_IMPERSONATION_UMASK = "0002"
READ_ONLY_ENV = "False"
PASSWORD_STORE = "DB"
# Project list for skip access check
PROJECT_LIST = ("ae6820eb-ff5e-4af9-b337-e7b60d9d16d2")

# limit percentage for scaling template
TEMPLATE_RESOURCE_CPU_LIMIT_PERCENTAGE = "40"
TEMPLATE_RESOURCE_MEMORY_LIMIT_PERCENTAGE = "40"


# Notebook storage path which is common for minio and notebook
NOTEBOOK_MOUNT_PATH="/sandbox_shared/logistics/notebooks/"

# resource request percentage for template
TEMPLATE_RESOURCE_MEMORY_REQUEST_PERCENTAGE = "10"
TEMPLATE_RESOURCE_CPU_REQUEST_PERCENTAGE = "10"
DELETE_SNAPSHOT_OLD_THAN_DAYS = 90

# Lens datasource
LENS_DATASOURCE="http://lens-datasource:80/lens-datasource"

# SAS temp working directory
SAS_TMP_WORDIR = "/output"

# Container High CPU Alert message
CPU_MORE_THAN_80_PERCENT = "Warning ::: CPU Utilization is more than 80% for past 5 mins for the template"
CPU_MORE_THAN_100_PERCENT = "CPU Utilization has reached 100% so the processes will run slower"

# Container cpu utilization percentage
CPU_PERCENT_HIGH_THRESHOLD1 = 25
CPU_PERCENT_HIGH_THRESHOLD2 = 40

# Container Alerts - Memory
MEMORY_PERCENT_HIGH_THRESHOLD1 = 80 
MEMORY_PERCENT_HIGH_THRESHOLD2 = 95
MEMORY_PERCENT_HIGH_THRESHOLD1_MESSAGE = "Your code has hit 80% of the maximum value if it reaches 100% process will get killed . please save your work"
MEMORY_PERCENT_HIGH_THRESHOLD2_MESSAGE = "Your code has hit 95% of the maximum value"

#Email notification
MEMORY_PERCENT_HIGH_THRESHOLD2_SUBJECT = "High Resource utilization"
MEMORY_PERCENT_HIGH_THRESHOLD2_ADDITIONAL_DESCRIPTION = "Email body"
EMAIL_TEMPLATE_ID = "cloud"
EMAIL_CONFIG_IDENTIFIER = "kw_cull_idle"
NOTIFICATION_URL = "http://notification-service/notification/v1/notification-add"
EMAIL_URL = "http://notification-service/notification/v1/notification/email"

REGISTRY_DIR_PATH_JUPYTER_36_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_37_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_38_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_39_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_3_10_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_38_SNOW_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTER_39_SNOW_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_37_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_38_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_39_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_3_10_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter"
REGISTRY_DIR_PATH_JUPYTERLAB_SPCS_3_10_IMAGE = "/refract_db/refract_schema/notebooks"
REGISTRY_DIR_PATH_R_JUPYTERLAB_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_R_JUPYTER_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_R_STUDIO_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager"
REGISTRY_DIR_PATH_SPARK_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_SPARK_JUPYTERLAB_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_SAS_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_VSCODE_JDK_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_VSCODE_SCALA_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_R_V4_1_2_STUDIO_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager"
REGISTRY_DIR_PATH_SPARK_DISTRIBUTED_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_R_STUDIO_RHEL_4_1_3_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager"
REGISTRY_DIR_PATH_SPARK_38_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_VSCODE_PYTHON_39_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build"
REGISTRY_DIR_PATH_PYTHON_PLUGIN_IMAGE =  "/mosaic-ai-logistics/mosaic-notebooks-manager"
CLASSIFICATION_ALGO = '{"sklearn.naive_bayes.GaussianNB": {}, "sklearn.naive_bayes.BernoulliNB": {"alpha": [0.001, 0.01, 0.1, 1.0, 10.0, {"sklearn.naive_bayes.GaussianNB": {}, "sklearn.naive_bayes.BernoulliNB": {"alpha": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], "fit_prior": [true, false]}, "sklearn.naive_bayes.MultinomialNB": {"alpha": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], "fit_prior": [true, false]}, "sklearn.tree.DecisionTreeClassifier": {"criterion": ["gini", "entropy"], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, "sklearn.ensemble.ExtraTreesClassifier": {"n_estimators": [100], "criterion": ["gini", "entropy"], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.ensemble.RandomForestClassifier": {"n_estimators": [100], "criterion": ["gini", "entropy"], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.ensemble.GradientBoostingClassifier": {"n_estimators": [100], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]}, "sklearn.neighbors.KNeighborsClassifier": {"n_neighbors": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], "weights": ["uniform", "distance"], "p": [1, 2]}, "sklearn.svm.LinearSVC": {"penalty": ["l1", "l2"], "loss": ["hinge", "squared_hinge"], "dual": [true, false], "tol": [1e-05, 0.0001, 0.001, 0.01, 0.1], "C": [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 15.0, 20.0, 25.0]}, "sklearn.linear_model.LogisticRegression": {"penalty": ["l1", "l2"], "C": [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 15.0, 20.0, 25.0], "dual": [true, false]}, "xgboost.XGBClassifier": {"n_estimators": [100], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_child_weight": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "n_jobs": [1], "verbosity": [0]}, "sklearn.linear_model.SGDClassifier": {"loss": ["log", "hinge", "modified_huber", "squared_hinge", "perceptron"], "penalty": ["elasticnet"], "alpha": [0.0, 0.01, 0.001], "learning_rate": ["invscaling", "constant"], "fit_intercept": [true, false], "l1_ratio": [0.25, 0.0, 1.0, 0.75, 0.5], "eta0": [0.1, 1.0, 0.01], "power_t": [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]}, "sklearn.neural_network.MLPClassifier": {"alpha": [0.0001, 0.001, 0.01, 0.1], "learning_rate_init": [0.001, 0.01, 0.1, 0.5, 1.0]}}], "fit_prior": [true, false]}, "sklearn.naive_bayes.MultinomialNB": {"alpha": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], "fit_prior": [true, false]}, "sklearn.tree.DecisionTreeClassifier": {"criterion": ["gini", "entropy"], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, "sklearn.ensemble.ExtraTreesClassifier": {"n_estimators": [100], "criterion": ["gini", "entropy"], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.ensemble.RandomForestClassifier": {"n_estimators": [100], "criterion": ["gini", "entropy"], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.ensemble.GradientBoostingClassifier": {"n_estimators": [100], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]}, "sklearn.neighbors.KNeighborsClassifier": {"n_neighbors": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], "weights": ["uniform", "distance"], "p": [1, 2]}, "sklearn.svm.LinearSVC": {"penalty": ["l1", "l2"], "loss": ["hinge", "squared_hinge"], "dual": [true, false], "tol": [1e-05, 0.0001, 0.001, 0.01, 0.1], "C": [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 15.0, 20.0, 25.0]}, "sklearn.linear_model.LogisticRegression": {"penalty": ["l1", "l2"], "C": [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 15.0, 20.0, 25.0], "dual": [true, false]}, "xgboost.XGBClassifier": {"n_estimators": [100], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_child_weight": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "n_jobs": [1], "verbosity": [0]}, "sklearn.linear_model.SGDClassifier": {"loss": ["log", "hinge", "modified_huber", "squared_hinge", "perceptron"], "penalty": ["elasticnet"], "alpha": [0.0, 0.01, 0.001], "learning_rate": ["invscaling", "constant"], "fit_intercept": [true, false], "l1_ratio": [0.25, 0.0, 1.0, 0.75, 0.5], "eta0": [0.1, 1.0, 0.01], "power_t": [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]}, "sklearn.neural_network.MLPClassifier": {"alpha": [0.0001, 0.001, 0.01, 0.1], "learning_rate_init": [0.001, 0.01, 0.1, 0.5, 1.0]}}'
REGRESSION_ALGO = '{"sklearn.linear_model.ElasticNetCV": {"l1_ratio": [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "tol": [1e-05, 0.0001, 0.001, 0.01, 0.1]}, "sklearn.ensemble.ExtraTreesRegressor": {"n_estimators": [100], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.ensemble.GradientBoostingRegressor": {"n_estimators": [100], "loss": ["ls", "lad", "huber", "quantile"], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "alpha": [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]}, "sklearn.ensemble.AdaBoostRegressor": {"n_estimators": [100], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "loss": ["linear", "square", "exponential"]}, "sklearn.tree.DecisionTreeRegressor": {"max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, "sklearn.neighbors.KNeighborsRegressor": {"n_neighbors": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], "weights": ["uniform", "distance"], "p": [1, 2]}, "sklearn.linear_model.LassoLarsCV": {"normalize": [true, false]}, "sklearn.svm.LinearSVR": {"loss": ["epsilon_insensitive", "squared_epsilon_insensitive"], "dual": [true, false], "tol": [1e-05, 0.0001, 0.001, 0.01, 0.1], "C": [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 15.0, 20.0, 25.0], "epsilon": [0.0001, 0.001, 0.01, 0.1, 1.0]}, "sklearn.ensemble.RandomForestRegressor": {"n_estimators": [100], "max_features": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "bootstrap": [true, false]}, "sklearn.linear_model.RidgeCV": {}, "xgboost.XGBRegressor": {"n_estimators": [100], "max_depth": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "learning_rate": [0.001, 0.01, 0.1, 0.5, 1.0], "subsample": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1], "min_child_weight": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "n_jobs": [1], "verbosity": [0], "objective": ["reg:squarederror"]}, "sklearn.linear_model.SGDRegressor": {"loss": ["squared_loss", "huber", "epsilon_insensitive"], "penalty": ["elasticnet"], "alpha": [0.0, 0.01, 0.001], "learning_rate": ["invscaling", "constant"], "fit_intercept": [true, false], "l1_ratio": [0.25, 0.0, 1.0, 0.75, 0.5], "eta0": [0.1, 1.0, 0.01], "power_t": [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]}}'
PROXY_ENABLED_GIT_PROVIDER = []
PROXY_DETAILS = "{\"Protocol\": \"https\", \"IPaddress\": \"\", \"UsernameOfProxy\":\"\", \"ProxyPassword\":\"\", \"SSLVerify\":false}"
SPARK_SUBMIT_COMMAND = "if [ $USE_KEYTAB_FILE ]; then echo kinit -k -t $SPARK_SUBMIT_KEYTAB_FILE_PATH $SPARK_SUBMIT_KEYTAB_USER;kinit -k -t $SPARK_SUBMIT_KEYTAB_FILE_PATH $SPARK_SUBMIT_KEYTAB_USER;if [[ $? == 1 ]];then exit 1;fi; else echo $SPARK_SUBMIT_KINIT_PASSWORD | kinit $SPARK_SUBMIT_KINIT_USERNAME;if [[ $? == 1 ]];then exit 1;fi; fi; echo spark-submit for {file_path}; echo spark-submit --master yarn --deploy-mode cluster --conf spark.port.maxRetries=100 --conf spark.pyspark.python='python' --driver-cores $SPARK_SUBMIT_DRIVER_CORES --num-executors $SPARK_SUBMIT_EXECUTORS_NO --executor-cores $SPARK_SUBMIT_EXECUTOR_CORES --driver-memory $SPARK_SUBMIT_DRIVER_MEMORY --executor-memory $SPARK_SUBMIT_EXECUTOR_MEMORY {file_path}; spark-submit --master yarn --deploy-mode cluster --conf spark.port.maxRetries=100 --conf spark.pyspark.python='python' --driver-cores $SPARK_SUBMIT_DRIVER_CORES --num-executors $SPARK_SUBMIT_EXECUTORS_NO --executor-cores $SPARK_SUBMIT_EXECUTOR_CORES --driver-memory $SPARK_SUBMIT_DRIVER_MEMORY --executor-memory $SPARK_SUBMIT_EXECUTOR_MEMORY {file_path} 2>&1;"

#Spawner config
PODNAME = "pod"
CONTAINERNAME = "container"
GIT_USERNAME = "root"
GIT_ACCESS_TOKEN = "VnPKvjyKoLjs7NF_g2sQ"
GIT_SERVER = "gitlab-ce.fdc-components.svc.cluster.local"
GIT_NAMESPACE = "root"
GIT_URL = "http://gitlab-ce.fdc-components.svc.cluster.local/root"
MONITOR_SERVICE_URL = "http://monitor-backend-service:80"
KUBERNETES_NAMESPACE= "insight"
KUBERNETES_NAMESPACE_KNIGHTS_WATCH = "insight"
DEFAULT_HOST = "qa.fdc.leni.ai"
DOCKER_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-ai-templates-ga:SchedulerExecutionV2.0.0"
SPARK_DOCKER_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build:SparkExecutionV1.1.1"
SYNC_SPARK_DOCKER_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build:AsyncSparkExecution5"
R_DOCKER_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-ai-templates-ga:SchedulerExecutionV2.0.0"
PYTHON_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-decisions-2-0/pre-post-hooks:python"
JAVA_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/workflow-service/workflow-engine:1.0.1-beta"
SHELL_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-decisions-2-0/pre-post-hooks:shell_1.0.0"
GIT_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-notebooks-manager/git:R20-1618-05mar24"
GIT_INIT_IMAGE = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-notebooks-manager/git:R20-1618-05mar24"

SPARK_USERNAME = "admin"
SPARK_PASSWORD = "Automation%40123"
CLUSTER_NAME = "mosaic.azurehdinsight.net"
BLOB_NAME = "mosaick8shdistorage.blob.core.windows.net"
FOLDER_NAME = "test"
BLOB_ACCOUNT_NAME = "mosaick8shdistorage"
BLOB_ACCOUNT_KEY = "CK5CpX7Y4WTbhvXY+IwBa3Lnyo1SPMGXoCI1lbS535oY43LHhBoj56a8zcCuIZAtA/hJIJQ/AxIGwXTNilb4ig=="
BLOB_CONTAINER_NAME = "mosaic-k8s-hdi-container"
DBT_SNOWFLAKE_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/dbt-snowflake:1.7.3.1.2"
DBT_DATABRICKS_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/dbt-databricks:1.6.4-4"

# experiment endpoints
AUTO_ML_DOCKER_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-auto-ml:v12"
AUTO_ML_SERVICE_URL = "http://auto-ml-service.insight.svc.cluster.local/auto-ml/api/v1/exp"

# AUTOML BACKEND URL
AUTOML_BACKEND_URL = "http://mosaic-automl-backend:8000/automl/api"    

# pyspark-version
PYSPARK_PYTHON = "/root/.pyenv/versions/3.7.5/bin/python"
PYSPARK3_PYTHON = "/root/.pyenv/versions/3.7.5/bin/python"

# backend url for spark sync/async
AI_SERVER_URL = "http://qa.fdc.leni.ai/registry/api"

# limit percentage
TEMPLATE_RESOURCE_CPU_LIMIT_PERCENTAGE = "40"
TEMPLATE_RESOURCE_MEMORY_LIMIT_PERCENTAGE = "40"

# resource request percentage
TEMPLATE_RESOURCE_MEMORY_REQUEST_PERCENTAGE = "10"
TEMPLATE_RESOURCE_CPU_REQUEST_PERCENTAGE = "10"

# prometheus endpoint
PROMETHEUS_URL = "http://prometheus-service.insight.svc.cluster.local:80/prometheus"

# monitor endpoint
MONITOR_URL="http://monitor-backend-service/monitor"

KNIGHTS_WATCH_IMAGE_NAME = "937361994640.dkr.ecr.us-east-1.amazonaws.com/mosaic-ai-logistics/mosaic-notebooks-manager/knights-watch:22.6.4"
CULL_IDLE_TIME_MINUTES = 120
CULL_CONFIG = '{"max_strikes":3, "interval_in_mins":30, "utilization_threshold_pct":50, "high_utilization_threshold_pct": 80, "send_to_cc": false, "email_config":{"subject": "Fosfor","template_url":"http://qa.fdc.leni.ai/ai/notebooks/{project_id}/template/{template_id}"}}'

KNIGHTS_WATCH_CONTAINER_LIMIT = '{"cpu": "1", "memory": "1Gi"}'
KNIGHTS_WATCH_CONTAINER_REQUEST = '{"cpu": "100m", "memory": "256Mi"}'

GIT_INIT_CONTAINER_LIMIT = '{"cpu": "1000m", "memory": "1Gi"}'
GIT_INIT_CONTAINER_REQUEST = '{"cpu": "100m", "memory": "256Mi"}'

# If ingress authentication fails, forword to this URL
INGRESS_AUTH_ERROR_PAGE = "http://qa.fdc.leni.ai/ai/access%20denied.html"

# ingress auth snippet to skip websocket request
INGRESS_AUTH_SNIPPET = "if ($HTTP_SEC_WEBSOCKET_KEY) {return 200;}"

# Project list for skip access check
PROJECT_LIST = ("9968fe47-6cd0-47b1-aab8-bdb4b091c116")

# spark on k8s operator
SPARK_ON_K8S_OPERATOR_URL = "https://refract-y3vtdcrk.hcp.centralindia.azmk8s.io:443/apis/sparkoperator.k8s.io/v1beta2/namespaces/spark/sparkapplications"
SPARK_K8S_BEARER = "Bearer Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlYwUFJ4RTlvSURzOEhGTi1fclM2cFJyWngzOVphejRIVEJFTEZlMTQzQzgifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJzcGFyayIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzcGFyay10b2tlbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJzcGFyay1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImE1M2FjZTYxLWEzOTAtNDA2NC05NjEwLWQyMDFjMGNiNWNlYSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpzcGFyazpzcGFyay1zYSJ9.pyOQbC6izj_2ColDHVEVNTkkwApPhGn-5lcMmXzi0NWMzKmNURK3GKBPLVEQ0mUnQCMewpvaCBhdj_gMiMfOpP6AtXNuNeESXcWUeL0v-u7HxErJxPxIoepAwUpcC2mf8h3PlaCjcBe_8ou-U8tzayGGeh9TI9PUraZfp6GhkMKM_I1qowfOc9yXAMbYlJKAB0OZ5069q_WpOf4P91-MpAhB4Uumplz11AVVAIgn1ItFoE4ic1xgszwgNyG7J_y4SiMX36YOg1_EsOwhJqHO2VyMTksjeNapj6rNPrKNpgi9ScA961zl2tMRayPXBKjVmxtBaccVzUqYgmr1hL_l39uudCSQXLeQW2WnOP7-7E0ogUy5VQM69BhJuyQPu8vPyuzbNp3blNSxOuTGdlvcuj05_JUCzjnmGjFHN_GLZ7VNg24TUG6wwr3Ednq3UoEZKFsE4c51-VH8yFzkxHR5USTRv9Soyo3nneUWhHbN5p9eiJTAyJPmasrvsSzXGnRJjmDbIayBbZz4rfzAq5yaWNKPqJCLj1wsaJ5otWeZvXAnwI8oim_OnnHZYuSikif5W-ookf_DWmD4yII1UBMnloHPJdnpaca9vttL7iUEXA-XkpYcBUKY5pCRI2bRXFEq5loXY1hH71wMNoydLrP_zQQANJT9_rlaWgIIEqJnEqg"
PYSPARK_BATCH_IMAGE = "mosaiccloudacr.azurecr.io/mosaic-ai-logistics/mosaic-notebooks-manager/spark-operator:so3.0.0_31082023"
PYSPARK_INIT_IMAGE = "mosaiccloudacr.azurecr.io/mosaic-ai-logistics/mosaic-notebooks-manager/mosaic-docker-build:pythonstandard3.6.2_1"
IMAGE_PULL_SECRETS = "gitlab"
INDEX_URL = "https://pypi.org/simple/"
OPERATOR_NAMESPACE = "spark"
SPARK_VOLUME_TYPE = "IP"
SPARK_OPERATOR_VERSION = "3.1.1"
SPARK_OPERATOR_SA = "spark-sa"
SPARK_OPERATOR_SHARED_PVC = "sparkoperator-pvc"

# PACKAGE REPO URL
PYPI_PACKAGE_REPO = "https://pypi.org/simple"
R_PACKAGE_REPO = "http://cran.us.r-project.org"
CONDA_PACKAGE_REPO = "https://repo.anaconda.com/pkgs/main/"
CONDA_R_PACKAGE_REPO = "conda-forge"

SERVICE_ACCOUNT_NAME = "default"
SERVICE_ACCOUNT_NAME_SPARK_DIST_TEMP = "spark-distributed-sa"

# workflow containers volume mount
WORKFLOW_PVC_NAME = "workflow-backend-pvc"

MINIO_DATA_BUCKET = "fdc-insights"
SHARED_PVC = "minio-pvc"

# ingress controller values nginx or alb
INGRESS_CONTROLLER = "nginx"
INGRESS_PATHTYPE = "Prefix"
ALB_GROUP_NAME = "mosaiccloudscblti"
ALB_INBOUND_CIDRS = "0.0.0.0/0"
ALB_LISTEN_PORTS = '{"HTTP": 80}'
ALB_SCHEME = "internet-facing"
ALB_TARGET_TYPE = "instance"
INGRESS_START_RANGE = 500
INGRESS_END_RANGE = 1000
SERVICE_TYPE = "NodePort"

# NodePool affinity.json folder
NODE_AFFINITY_FOLDER = "/refract/mosaic-notebooks-manager/app/notebooks_api/configs"

# host alias for ADS connectivity
# format: '{"hostAliases": [{"ip": "127.0.0.5", "hostnames": ["foo.local", "bar.local"]}, {"ip": "127.0.0.6", "hostnames": ["foo.local2", "bar.local2"]}]}'
ADS_CONFIG = ""

RETRY_COUNT = 5
RETRY_DELAY = 5
TEMPLATE_NAS_DIRECTORY = "/packages"
IMAGE_PULL_SECRETS = "gitlab"

# HaaS Interactive configs for spark
# SPARK_DRIVER_HOSTS = "<semicolon separated list of master node IPs>"
NODEPORT_START_RANGE = 30100 # Configure this range based on environment, ideal to have zero nodeports already occupied
NODEPORT_END_RANGE = 30999
MAX_ALLOWED_NODEPORTS = 100

# mlflow experiment template dependency packages
MLFLOW_DEPENDENCY_PACKAGES = " refractio==2.1.5.5 refract-mlflow-plugin==1.0.2 tpot==0.12.1 "

#vcs config
PROPAGATE_EXCEPTIONS = True
GIT_STORAGE_TYPE = "DB"
GIT_PROVIDER = "gitlab"
GIT_PUBLIC_URL = "http://gitlab-ce.fdc-components.svc.cluster.local"
DEFAULT_GIT_BRANCH = "master"
REMOTE_URL = "http://gitlab-ce.fdc-components.svc.cluster.local/root"
PROJECT_KEY = "root"
GIT_PASSWORD = "VnPKvjyKoLjs7NF_g2sQ"
GIT_BITBUCKET_API_AUTH_USER = ""
GIT_BITBUCKET_API_AUTH_PASS = ""
NOTEBOOKS_API_URL = "http://notebooks-api:5000/notebooks/api"

 # job deletion duration - ttl parameter
TTL_SECONDS_AFTER_FINISHED = 600